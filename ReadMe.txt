Following the Data Pipeline process is an extremely important process of any Data Analysis.
We have several tools and languages at our disposal for implementing the data pipeline process, including:

SQL (PostgreSQL DBMS)
Python (Juypter Notebook)
R (RStudio)

In my analysis of the airline database, I have decided to implement all 3 tools for different purposes, considering 
the fact that each language has it's own strengths and weakness. 

Data Wrangling 
SQL will be used to clean and transform the dataset into a more understandable form for preliminary data analytics.
This is because of SQL's performance, ease of use and scalability, and the fact that our airline data set is very large. SQL is built on relational algrebra,
meaning it's performance with large datasets is superb.

Data Exploration
R is selected for exploration because of the tidyverse readability and efficiency.

Machine Modelling 
Python is selected for machine learning because of Scikit Learn machine learning pipeline capability.

Interpretation of results
R is selected for communication because of the advanced reporting utilities including RMarkdown and Shiny (interactive web apps)
and the wonderful ggplot2 visualization package.